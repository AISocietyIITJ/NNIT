from torch import nn

class Encoder(nn.module):
  '''
  Vision Transformer style encoder which returns 
  patch_level representations of the input image
  '''
  def__init__(image_size,embedding_size,n_heads,patch_size):
    super().__init__()
  def forward(self,input):
    pass
