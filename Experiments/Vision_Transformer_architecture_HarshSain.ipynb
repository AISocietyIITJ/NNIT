{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU3Tc7E_eBlZ",
        "outputId": "c50b5a6e-34ac-4b67-bfe2-a57d7511ae70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 <command> [options]\n",
            "\n",
            "Commands:\n",
            "  install                     Install packages.\n",
            "  download                    Download packages.\n",
            "  uninstall                   Uninstall packages.\n",
            "  freeze                      Output installed packages in requirements format.\n",
            "  inspect                     Inspect the python environment.\n",
            "  list                        List installed packages.\n",
            "  show                        Show information about installed packages.\n",
            "  check                       Verify installed packages have compatible dependencies.\n",
            "  config                      Manage local and global configuration.\n",
            "  search                      Search PyPI for packages.\n",
            "  cache                       Inspect and manage pip's wheel cache.\n",
            "  index                       Inspect information available from package indexes.\n",
            "  wheel                       Build wheels from your requirements.\n",
            "  hash                        Compute hashes of package archives.\n",
            "  completion                  A helper command used for command completion.\n",
            "  debug                       Show information useful for debugging.\n",
            "  help                        Show help for commands.\n",
            "\n",
            "General Options:\n",
            "  -h, --help\n",
            "  Show help.\n",
            "  --debug\n",
            "  Let\n",
            "  unhandled\n",
            "  exceptions\n",
            "  propagate\n",
            "  outside the\n",
            "  main\n",
            "  subroutine,\n",
            "  instead of\n",
            "  logging\n",
            "  them to\n",
            "  stderr.\n",
            "  --isolated\n",
            "  Run pip in\n",
            "  an isolated\n",
            "  mode,\n",
            "  ignoring\n",
            "  environment\n",
            "  variables\n",
            "  and user co\n",
            "  nfiguration\n",
            "  .\n",
            "  --require-virtualenv\n",
            "  Allow pip\n",
            "  to only run\n",
            "  in a\n",
            "  virtual env\n",
            "  ironment;\n",
            "  exit with\n",
            "  an error\n",
            "  otherwise.\n",
            "  --python <python>\n",
            "  Run pip\n",
            "  with the\n",
            "  specified\n",
            "  Python inte\n",
            "  rpreter.\n",
            "  -v, --verbose\n",
            "  Give more\n",
            "  output.\n",
            "  Option is\n",
            "  additive,\n",
            "  and can be\n",
            "  used up to\n",
            "  3 times.\n",
            "  -V, --version\n",
            "  Show\n",
            "  version and\n",
            "  exit.\n",
            "  -q, --quiet\n",
            "  Give less\n",
            "  output.\n",
            "  Option is\n",
            "  additive,\n",
            "  and can be\n",
            "  used up to\n",
            "  3 times (co\n",
            "  rresponding\n",
            "  to WARNING,\n",
            "  ERROR, and\n",
            "  CRITICAL\n",
            "  logging\n",
            "  levels).\n",
            "  --log <path>\n",
            "  Path to a\n",
            "  verbose\n",
            "  appending\n",
            "  log.\n",
            "  --no-input\n",
            "  Disable\n",
            "  prompting\n",
            "  for input.\n",
            "  --keyring-provider <keyring_provider>\n",
            "  Enable the\n",
            "  credential\n",
            "  lookup via\n",
            "  the keyring\n",
            "  library if\n",
            "  user input\n",
            "  is allowed.\n",
            "  Specify\n",
            "  which\n",
            "  mechanism\n",
            "  to use\n",
            "  [disabled,\n",
            "  import, sub\n",
            "  process].\n",
            "  (default:\n",
            "  disabled)\n",
            "  --proxy <proxy>\n",
            "  Specify a\n",
            "  proxy in\n",
            "  the form sc\n",
            "  heme://[use\n",
            "  r:passwd@]p\n",
            "  roxy.server\n",
            "  :port.\n",
            "  --retries <retries>\n",
            "  Maximum\n",
            "  number of\n",
            "  retries\n",
            "  each\n",
            "  connection\n",
            "  should\n",
            "  attempt\n",
            "  (default 5\n",
            "  times).\n",
            "  --timeout <sec>\n",
            "  Set the\n",
            "  socket\n",
            "  timeout\n",
            "  (default 15\n",
            "  seconds).\n",
            "  --exists-action <action>\n",
            "  Default\n",
            "  action when\n",
            "  a path\n",
            "  already\n",
            "  exists:\n",
            "  (s)witch,\n",
            "  (i)gnore,\n",
            "  (w)ipe,\n",
            "  (b)ackup,\n",
            "  (a)bort.\n",
            "  --trusted-host <hostname>\n",
            "  Mark this\n",
            "  host or\n",
            "  host:port\n",
            "  pair as\n",
            "  trusted,\n",
            "  even though\n",
            "  it does not\n",
            "  have valid\n",
            "  or any\n",
            "  HTTPS.\n",
            "  --cert <path>\n",
            "  Path to\n",
            "  PEM-encoded\n",
            "  CA\n",
            "  certificate\n",
            "  bundle. If\n",
            "  provided,\n",
            "  overrides\n",
            "  the\n",
            "  default.\n",
            "  See 'SSL\n",
            "  Certificate\n",
            "  Verificatio\n",
            "  n' in pip d\n",
            "  ocumentatio\n",
            "  n for more \n",
            "  information\n",
            "  .\n",
            "  --client-cert <path>\n",
            "  Path to SSL\n",
            "  client cert\n",
            "  ificate, a\n",
            "  single file\n",
            "  containing\n",
            "  the private\n",
            "  key and the\n",
            "  certificate\n",
            "  in PEM\n",
            "  format.\n",
            "  --cache-dir <dir>\n",
            "  Store the\n",
            "  cache data\n",
            "  in <dir>.\n",
            "  --no-cache-dir\n",
            "  Disable the\n",
            "  cache.\n",
            "  --disable-pip-version-check\n",
            "  Don't perio\n",
            "  dically\n",
            "  check PyPI\n",
            "  to\n",
            "  determine\n",
            "  whether a\n",
            "  new version\n",
            "  of pip is\n",
            "  available\n",
            "  for\n",
            "  download.\n",
            "  Implied\n",
            "  with --no-\n",
            "  index.\n",
            "  --no-color\n",
            "  Suppress\n",
            "  colored\n",
            "  output.\n",
            "  --no-python-version-warning\n",
            "  Silence\n",
            "  deprecation\n",
            "  warnings\n",
            "  for\n",
            "  upcoming\n",
            "  unsupported\n",
            "  Pythons.\n",
            "  --use-feature <feature>\n",
            "  Enable new \n",
            "  functionali\n",
            "  ty, that\n",
            "  may be\n",
            "  backward in\n",
            "  compatible.\n",
            "  --use-deprecated <feature>\n",
            "  Enable\n",
            "  deprecated \n",
            "  functionali\n",
            "  ty, that\n",
            "  will be\n",
            "  removed in\n",
            "  the future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t35l9gI0eBiD",
        "outputId": "c0c17cf6-f6a5-47f4-da90-ac18e02edce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apt 2.0.9 (amd64)\n",
            "Usage: apt [options] command\n",
            "\n",
            "apt is a commandline package manager and provides commands for\n",
            "searching and managing as well as querying information about packages.\n",
            "It provides the same functionality as the specialized APT tools,\n",
            "like apt-get and apt-cache, but enables options more suitable for\n",
            "interactive use by default.\n",
            "\n",
            "Most used commands:\n",
            "  list - list packages based on package names\n",
            "  search - search in package descriptions\n",
            "  show - show package details\n",
            "  install - install packages\n",
            "  reinstall - reinstall packages\n",
            "  remove - remove packages\n",
            "  autoremove - Remove automatically all unused packages\n",
            "  update - update list of available packages\n",
            "  upgrade - upgrade the system by installing/upgrading packages\n",
            "  full-upgrade - upgrade the system by removing/installing/upgrading packages\n",
            "  edit-sources - edit the source information file\n",
            "  satisfy - satisfy dependency strings\n",
            "\n",
            "See apt(8) for more information about the available commands.\n",
            "Configuration options and syntax is detailed in apt.conf(5).\n",
            "Information about how to configure sources can be found in sources.list(5).\n",
            "Package and version choices can be expressed via apt_preferences(5).\n",
            "Security details are available in apt-secure(8).\n",
            "                                        This APT has Super Cow Powers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J9Rn8rbr0eT",
        "outputId": "17ef590b-135b-46de-9f49-8f83fa956101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.16)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "pip install opendatasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKYRUQDld-Ox",
        "outputId": "29ed0bb1-20c6-4dc9-b3fc-7ba97e2320b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/preatcher/standard-ocr-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsB8zSL4CSWT",
        "outputId": "35a120ff-4b53-4834-8568-7dc95fd20c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: harshsainb21me028\n",
            "Your Kaggle Key: ··········\n",
            "Downloading standard-ocr-dataset.zip to ./standard-ocr-dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 46.2M/46.2M [00:02<00:00, 21.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Gk5RKvNpdAd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import DatasetFolder\n",
        "from torchvision.models import resnet50\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class patchEmbed(nn.Module):\n",
        "    def __init__ (self, img_size , patch_size, in_chans = 3, embed_dim = 768):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.n_patches = (img_size // patch_size)**2\n",
        "\n",
        "        self.proj = nn.Conv2d(\n",
        "            in_chans,\n",
        "            embed_dim,\n",
        "            kernal_size = patch_size,\n",
        "            stride = patch_size,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(\n",
        "            x\n",
        "        )\n",
        "        x = x.flatten(2)\n",
        "        x = x.transpose(1,2)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "bymOGDBCXWi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, n_heads = 12, qkv_bias = True, attn_p = 0. , proj_p = 0.):\n",
        "        super().__init__()\n",
        "        self.n_head = n_heads\n",
        "        self.dim = dim // n_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.linear(dim, dim *3 , bias = qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_p)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_samples, n_tokens, dim = x.shape\n",
        "\n",
        "        if dim != self.dim:\n",
        "            raise ValueError\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.reshape(\n",
        "            n_samples, n_tokens,3 , self.n_heads, self.head_dim\n",
        "        )\n",
        "        qkv = qkv.permute(\n",
        "            2,0,3,1,4\n",
        "        )\n",
        "        q, k , v = qkv[0],qkv[1],qkv[2]\n",
        "        k_t = k.transpose(-2,-1)\n",
        "        dp = (\n",
        "            q @ k_t\n",
        "        )*self.scale\n",
        "        attn = dp.softmax(dim = 1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        weighted_avg = attn @ v\n",
        "        weighted_avg = weighted_avg.transpose(\n",
        "            1,2\n",
        "        )\n",
        "        weighted_avg = weighted_avg.flatten(\n",
        "            2\n",
        "        )\n",
        "\n",
        "        x = self.proj(weighted_avg)\n",
        "        x = self.proj_drop(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "fIsBg6bIXa4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features, p=0.):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features , hidden_features)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "33EDZqLpXfao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, n_heads , mlp_ratio = 4.0, qkv_bias = True, attn_p = 0. , p = 0.):\n",
        "        super.__int__()\n",
        "        self.norm1 = nn.LayerNorm(dim,eps = 1e-6)\n",
        "        self.attn = Attention(\n",
        "            dim,\n",
        "            n_heads = n_heads,\n",
        "            qkv_bias = qkv_bias,\n",
        "            attn_p = attn_p,\n",
        "            proj_p = p\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(dim, eps = 1e-6)\n",
        "        hidden_features = int(dim*mlp_ratio)\n",
        "        self.mlp = MLP(\n",
        "            in_featurea = dim,\n",
        "            hidden_features = hidden_features,\n",
        "            out_featrures = dim,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "J21nfNTPXiZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                img_size = 384,\n",
        "                patch_size = 16,\n",
        "                in_chans = 3,\n",
        "                embed_dim = 768,\n",
        "                depth = 12,\n",
        "                n_heads = 12,\n",
        "                mlp_ratio = 4 ,\n",
        "                qkv_bias = True,\n",
        "                p =0.,\n",
        "                attn_p = 0. ,\n",
        "      ):\n",
        "        super().__init__()\n",
        "        self.patch_embed = patchEmbed(\n",
        "            img_size = img_size,\n",
        "            patch_size = patch_size,\n",
        "            in_chans = in_chans,\n",
        "            embed_dim =embed_dim,\n",
        "        )\n",
        "        self.cls_token = nn.parameter(torch.zeros(1,1,embed_dim))\n",
        "        self.pos_embed = nn.parameter(\n",
        "            torch.zeroes(1, 1 + self.patch_embed.n_patches, embed_dim)\n",
        "        )\n",
        "        self.pos_drop = nn.Dropout(p = p)\n",
        "\n",
        "        self.blocks =Block(\n",
        "                    dim = embed_dim,\n",
        "                    n_heads = n_heads,\n",
        "                    mlp_ratio = mlp_ratio,\n",
        "                    qkv_bias = qkv_bais,\n",
        "                    p = p,\n",
        "                    attn_p = attn_p,\n",
        "                  )\n",
        "\n",
        "        self.norm = nn.LayerNorm(embed_dim, eps = 1e-6)\n",
        "        self.head = nn.Linear(embed_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        n_samples = x.shapes[0]\n",
        "        x= self.patch_embed(x)\n",
        "\n",
        "        cls_token = self.cls_token.expend(\n",
        "            n_samples, -1,-1\n",
        "        )\n",
        "        x = torch.cat((cls_token, x), dim = 1)\n",
        "        x = x + self.pos_embed\n",
        "        print(x.shape, self.pos_embed.shape)\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.norm(x)\n",
        "\n",
        "        cls_token_final = x[:, 0]\n",
        "        x =self.head(cls_token_final)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "6p9vvepjYBmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuu1vkhsqdeN"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the Kaggle dataset\n",
        "import torchvision\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "traindataset = DatasetFolder('/content/standard-ocr-dataset/data/training_data', loader=torchvision.datasets.folder.default_loader, transform=transform,extensions = 'png')\n",
        "train_dataset,val_dataset=torch.utils.data.random_split(traindataset,(0.8,0.2))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "ZirRJy_Xqj3y",
        "outputId": "d186c61c-77d3-434a-9ea9-0b2fb98ce8e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-20329d0faf0b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVisionTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define loss function and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-6f90f58c9c89>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_size, patch_size, in_chans, embed_dim, depth, n_heads, mlp_ratio, qkv_bias, p, attn_p)\u001b[0m\n\u001b[1;32m     13\u001b[0m       ):\n\u001b[1;32m     14\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         self.patch_embed = patchEmbed(\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mpatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-5a794ccfeb08>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_size, patch_size, in_chans, embed_dim)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_patches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         self.proj = nn.Conv2d(\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0min_chans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Conv2d.__init__() got an unexpected keyword argument 'kernal_size'"
          ]
        }
      ],
      "source": [
        "\n",
        "model = VisionTransformer()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images,labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    val_loss /= len(val_loader)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "print(\"Training finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx1TO6oMq1wD"
      },
      "outputs": [],
      "source": [
        "# Testing\n",
        "test_dataset = DatasetFolder('/content/standard-ocr-dataset/data/training_data', loader=torchvision.datasets.folder.default_loader, transform=transform,extensions = 'png')\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        images = images.to(device)\n",
        "        # # outputs = model(images)\n",
        "        # _, predicted = torch.max(outputs.data, 1)\n",
        "        # predictions.extend(predicted.cpu().numpy())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}