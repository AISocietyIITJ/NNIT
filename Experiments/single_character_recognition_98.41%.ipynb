{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d21b9985",
   "metadata": {},
   "source": [
    "### Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb2b298-4152-4a61-9f09-eef06233662f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "050a3ae7-839a-4af7-b9e0-1f04e49f12ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b39b27ad",
   "metadata": {},
   "source": [
    "### Creating dataloaders from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e7dcd04-cce1-4d7c-a32d-ba59e955e756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "540c71d9-7897-40da-81c5-dce1a7e3432a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dataset_path = 'new_data/training_data/'\n",
    "testing_dataset_path = 'new_data/testing_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e71e6969-5567-4add-bda0-ae25a9c31dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "characters = os.listdir(training_dataset_path)\n",
    "\n",
    "# characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "201ea027-8f70-414f-8986-34a454c9a948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_dict = dict()\n",
    "for each in range(len(characters)):\n",
    "    labels_dict[characters[each]] = each\n",
    "    \n",
    "# labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7251bf5-a662-4441-8d44-d06f9ad9c99e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(characters)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a07989-47b5-47b6-8b69-811578cdbafb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_compiler(dataset_path):\n",
    "    dataset = []\n",
    "\n",
    "    for character in characters:\n",
    "        character_path = os.path.join(dataset_path, character)\n",
    "        # print(character_path)\n",
    "\n",
    "        for character_image in os.listdir(character_path):\n",
    "            image_path = os.path.join(character_path, character_image)\n",
    "\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            # resizing the image\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            # plt.imshow(img)\n",
    "            # converting to tensor\n",
    "            img = torch.tensor(img).view(-1, IMG_SIZE*IMG_SIZE)\n",
    "            # scaling the data\n",
    "            img = (img/255.0)\n",
    "\n",
    "            # print(img.shape)\n",
    "            dataset.append([img, np.eye(num_labels)[labels_dict[character]]])\n",
    "            \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c18ce673-c32f-4e78-ab13-0f3b5af6923b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20628"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = data_compiler(training_dataset_path)\n",
    "len(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d763ba3-2cf6-4927-ac68-3899847805df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_dataset = data_compiler(testing_dataset_path)\n",
    "len(testing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a72c4c30-27c1-492d-9999-9135190242fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90607626-e8de-44e0-9ae7-71879dec491a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d2d6709-e484-47c5-9c7c-8fd0afd1777e",
   "metadata": {},
   "source": [
    "### Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e705cd2-0d80-4f1e-a712-5b5819c2bad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_labels, img_size=IMG_SIZE):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        x = torch.rand(self.img_size, self.img_size).view(-1,1,self.img_size,self.img_size)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 256)\n",
    "        self.fc2 = nn.Linear(256, self.num_labels)\n",
    "        \n",
    "    def convs(self, x):\n",
    "        x = x.view(-1,1,self.img_size,self.img_size)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), kernel_size=2)\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = 1\n",
    "            for each in range(len(x[0].shape)):\n",
    "                self._to_linear *= x[0].shape[each]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def save(self, path='best_model.pth'):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path='best_model.pth'):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        self.eval()\n",
    "        \n",
    "    def fit(self, train_loader, optimizer=Adam, loss_function=CrossEntropyLoss(), learning_rate=0.001, epochs=5):\n",
    "        min_loss = float('inf')\n",
    "        self.optimizer = optimizer(self.parameters(), lr=learning_rate)\n",
    "        self.loss_func = loss_function\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            for batch in train_loader:\n",
    "                train_X, train_y = batch\n",
    "                pred_train_y = self.forward(train_X)\n",
    "                \n",
    "                loss = self.loss_func(pred_train_y, train_y)\n",
    "                \n",
    "                # self.zero_grad()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            print(f'epoch={epoch+1}: loss={loss}')\n",
    "            # if loss < min_loss:\n",
    "            #     self.save()\n",
    "            #     min_loss = loss\n",
    "\n",
    "        self.save()\n",
    "        \n",
    "    def test(self, test_loader):\n",
    "        self.load()\n",
    "        \n",
    "        total = len(test_loader.dataset)\n",
    "        correct = 0\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            test_X, test_y = batch\n",
    "            pred_test_y = self.forward(test_X)\n",
    "\n",
    "            for each in range(len(test_y)):\n",
    "                pred = torch.argmax(pred_test_y, 1)[each]\n",
    "                true = torch.argmax(test_y, 1)[each]\n",
    "                if pred == true:\n",
    "                    correct += 1\n",
    "                    \n",
    "        print(f'accuracy: {correct/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b396129-574e-4262-82b6-7af652f7f469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ConvNet(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f0da8c5-c94f-4d99-b735-41bb4ed836a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1152, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=36, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdd917a7-be16-4c9f-ad0a-18f07606cace",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 1/10 [00:08<01:14,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1: loss=0.2724030649596898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 2/10 [00:16<01:06,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2: loss=0.036471910066134684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████▏                              | 3/10 [00:25<00:58,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3: loss=0.17302121353717723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▌                          | 4/10 [00:33<00:50,  8.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4: loss=0.14086763261720706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████                      | 5/10 [00:41<00:41,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5: loss=0.05776092280353815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████▍                 | 6/10 [00:50<00:33,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6: loss=0.08216436571560984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████▊             | 7/10 [00:58<00:25,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7: loss=0.09234200793607492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████▏        | 8/10 [01:06<00:16,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8: loss=0.020000559640224225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████▌    | 9/10 [01:15<00:08,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9: loss=0.07627599721255648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [01:23<00:00,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10: loss=0.00034006594659850007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataloader, learning_rate=0.001, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df5e24d0-ae89-4143-883a-8e1873269c19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9841269841269841\n"
     ]
    }
   ],
   "source": [
    "model.test(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ff331-b076-434a-8a14-e26bd7c03372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
