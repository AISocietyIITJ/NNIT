{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxkF07PtwnG7DYHKm4Vp6n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parisharma16/PariSharma-iitj.github.io/blob/main/TASK_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkCNUolyXs77",
        "outputId": "d7877f3c-6ab0-49e8-c25b-ad6ec8c741a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REBUILD_DATA =True # set to true to one once, then back to false unless you want to change something in your training data.\n",
        "\n",
        "class Alpha_num():\n",
        "    IMG_SIZE = 50\n",
        "    training_data_path =\"/content/gdrive/MyDrive/data/training_data/\"\n",
        "    N0 =\"/content/gdrive/MyDrive/data/training_data/0\"\n",
        "    N1 =\"/content/gdrive/MyDrive/data/training_data/1\"\n",
        "    N2 =\"/content/gdrive/MyDrive/data/training_data/2\"\n",
        "    N3 =\"/content/gdrive/MyDrive/data/training_data/3\"\n",
        "    N4 =\"/content/gdrive/MyDrive/data/training_data/4\"\n",
        "    N5 =\"/content/gdrive/MyDrive/data/training_data/5\"\n",
        "    N6 =\"/content/gdrive/MyDrive/data/training_data/6\"\n",
        "    N7 =\"/content/gdrive/MyDrive/data/training_data/7\"\n",
        "    N8 =\"/content/gdrive/MyDrive/data/training_data/8\"\n",
        "    N9 =\"/content/gdrive/MyDrive/data/training_data/9\"\n",
        "    A=\"/content/gdrive/MyDrive/data/training_data/A\"\n",
        "    B=\"/content/gdrive/MyDrive/data/training_data/B\"\n",
        "    C=\"/content/gdrive/MyDrive/data/training_data/C\"\n",
        "    D=\"/content/gdrive/MyDrive/data/training_data/D\"\n",
        "    E=\"/content/gdrive/MyDrive/data/training_data/E\"\n",
        "    F=\"/content/gdrive/MyDrive/data/training_data/F\"\n",
        "    G=\"/content/gdrive/MyDrive/data/training_data/G\"\n",
        "    H=\"/content/gdrive/MyDrive/data/training_data/H\"\n",
        "    I=\"/content/gdrive/MyDrive/data/training_data/I\"\n",
        "    J=\"/content/gdrive/MyDrive/data/training_data/J\"\n",
        "    K=\"/content/gdrive/MyDrive/data/training_data/K\"\n",
        "    L=\"/content/gdrive/MyDrive/data/training_data/L\"\n",
        "    M=\"/content/gdrive/MyDrive/data/training_data/M\"\n",
        "    N=\"/content/gdrive/MyDrive/data/training_data/N\"\n",
        "    O=\"/content/gdrive/MyDrive/data/training_data/O\"\n",
        "    P=\"/content/gdrive/MyDrive/data/training_data/P\"\n",
        "    Q=\"/content/gdrive/MyDrive/data/training_data/Q\"\n",
        "    R=\"/content/gdrive/MyDrive/data/training_data/R\"\n",
        "    S=\"/content/gdrive/MyDrive/data/training_data/S\"\n",
        "    T=\"/content/gdrive/MyDrive/data/training_data/T\"\n",
        "    U=\"/content/gdrive/MyDrive/data/training_data/U\"\n",
        "    V=\"/content/gdrive/MyDrive/data/training_data/V\"\n",
        "    W=\"/content/gdrive/MyDrive/data/training_data/W\"\n",
        "    X=\"/content/gdrive/MyDrive/data/training_data/X\"\n",
        "    Y=\"/content/gdrive/MyDrive/data/training_data/Y\"\n",
        "    Z=\"/content/gdrive/MyDrive/data/training_data/Z\"\n",
        "\n",
        "    #LABELS = {N0:0,'N1':1,'N2':2,'N3':3,'N4':4,'N5':5,'N6':6,'N7':7,'N8':8,'N9':9,'A':10,'B':11,'C':12,'D':13,'E':14,'F':15,'G':16,'H':17,'I':18,'J':19,'K':20,'L':21,'M':22,'N':23,'O':24,'P':25,'Q':26,'R':27,'S':28,'T':29,'U':30,'V':31,'W':32,'X':33,'Y':34,'Z':35}\n",
        "    LABELS = {N0:0,N1:1,N2:2,N3:3,N4:4,N5:5,N6:6,N7:7,N8:8,N9:9,A:10,B:11,C:12,D:13,E:14,F:15,G:16,H:17,I:18,J:19,K:20,L:21,M:22,N:23,O:24,P:25,Q:26,R:27,S:28,T:29,U:30,V:31,W:32,X:33,Y:34,Z:35}\n",
        "    #COUNTS = {N0:0,'N1':0,'N2':0,'N3':0,'N4':0,'N5':0,'N6':0,'N7':0,'N8':0,'N9':0,'A':0,'B':0,'C':0,'D':0,'E':0,'F':0,'G':0,'H':0,'I':0,'J':0,'K':0,'L':0,'M':0,'N':0,'O':0,'P':0,'Q':0,'R':0,'S':0,'T':0,'U':0,'V':0,'W':0,'X':0,'Y':0,'Z':0}\n",
        "    COUNTS = {N0:0,N1:0,N2:0,N3:0,N4:0,N5:0,N6:0,N7:0,N8:0,N9:0,A:0,B:0,C:0,D:0,E:0,F:0,G:0,H:0,I:0,J:0,K:0,L:0,M:0,N:0,O:0,P:0,Q:0,R:0,S:0,T:0,U:0,V:0,W:0,X:0,Y:0,Z:0}\n",
        "\n",
        "    training_data = []\n",
        "\n",
        "\n",
        "    def make_training_data(self):\n",
        "        for label in self.LABELS:\n",
        "            for f in tqdm(os.listdir(label)):         #for f in tqdm(os.listdir(self.training_data_path)):\n",
        "                    try:\n",
        "                        path = os.path.join(label, f)\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                        self.training_data.append([np.array(img), np.eye(36)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot\n",
        "                        #print(np.eye(36)[self.LABELS[label]])\n",
        "                        for count in self.COUNTS:\n",
        "                          if label==count:\n",
        "                            self.COUNTS[count]+=1\n",
        "                    except Exception as e:\n",
        "                          pass\n",
        "\n",
        "\n",
        "        np.random.shuffle(self.training_data)\n",
        "        np.save(\"training_data.npy\", self.training_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")\n",
        "\n",
        "\n",
        "if REBUILD_DATA:\n",
        "    alphavsnum = Alpha_num()\n",
        "    alphavsnum.make_training_data()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STA8VaLfZCPo",
        "outputId": "edb0acb7-16fb-4f41-9127-eaad1532e415"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on the GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 573/573 [00:09<00:00, 59.33it/s] \n",
            "100%|██████████| 574/574 [00:08<00:00, 65.53it/s] \n",
            "100%|██████████| 573/573 [00:08<00:00, 65.55it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 80.88it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 87.57it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 80.64it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 87.87it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 76.94it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 88.39it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 85.35it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 84.79it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 75.59it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 88.51it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 77.23it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 85.70it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 74.77it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 93.81it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 80.70it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 75.06it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 77.76it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 92.64it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 84.37it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 84.55it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 89.54it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 83.83it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 92.59it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 95.21it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 88.09it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 80.23it/s] \n",
            "100%|██████████| 573/573 [00:08<00:00, 67.15it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 77.29it/s] \n",
            "100%|██████████| 573/573 [00:07<00:00, 78.72it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 86.57it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 92.16it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 90.66it/s] \n",
            "100%|██████████| 573/573 [00:06<00:00, 83.53it/s] \n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "\n",
        "        x = torch.randn(50,50).view(-1,1,50,50)\n",
        "        self._to_linear = None\n",
        "        self.convs(x)\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, 36)\n",
        "\n",
        "    def convs(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
        "\n",
        "        if self._to_linear is None:\n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1, self._to_linear)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "a_nI8CrmdPo4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "MqX947y5dQjE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
        "#print(len(training_data))"
      ],
      "metadata": {
        "id": "wVwMDiLXd_oY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()"
      ],
      "metadata": {
        "id": "Y399XU0fkr_Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50)\n",
        "X = X/255.0\n",
        "y = torch.Tensor([i[1] for i in training_data])\n",
        "\n",
        "train_X = X\n",
        "train_y = y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRVN7k4Jjf30",
        "outputId": "e62aa208-80bc-4839-f4de-3aa42a91454f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-7b1aaeec5945>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net):\n",
        "    BATCH_SIZE = 50   #100\n",
        "    EPOCHS = 10\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
        "            batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
        "            batch_y = train_y[i:i+BATCH_SIZE]\n",
        "\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "            net.zero_grad()\n",
        "            outputs = net(batch_X)\n",
        "            loss = loss_function(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(loss)"
      ],
      "metadata": {
        "id": "UaWrezwJkWfS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvQ8TblVkXS2",
        "outputId": "d35ccac7-4a8b-4431-869a-a72d5e491cb3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 413/413 [00:01<00:00, 220.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 413/413 [00:01<00:00, 227.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0001, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 413/413 [00:01<00:00, 227.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 413/413 [00:01<00:00, 226.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.3002e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 413/413 [00:01<00:00, 219.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8239e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 413/413 [00:01<00:00, 219.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 413/413 [00:01<00:00, 223.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 413/413 [00:01<00:00, 225.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0002, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 413/413 [00:01<00:00, 226.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0003, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 413/413 [00:01<00:00, 226.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REBUILD_DATA_test =True # set to true to one once, then back to false unless you want to change something in your training data.\n",
        "\n",
        "\n",
        "class Alpha_num_test():\n",
        "    IMG_SIZE = 50\n",
        "    testing_data_path =\"/content/gdrive/MyDrive/data/testing_data/\"\n",
        "    N0 =\"/content/gdrive/MyDrive/data/testing_data/0\"\n",
        "    N1 =\"/content/gdrive/MyDrive/data/testing_data/1\"\n",
        "    N2 =\"/content/gdrive/MyDrive/data/testing_data/2\"\n",
        "    N3 =\"/content/gdrive/MyDrive/data/testing_data/3\"\n",
        "    N4 =\"/content/gdrive/MyDrive/data/testing_data/4\"\n",
        "    N5 =\"/content/gdrive/MyDrive/data/testing_data/5\"\n",
        "    N6 =\"/content/gdrive/MyDrive/data/testing_data/6\"\n",
        "    N7 =\"/content/gdrive/MyDrive/data/testing_data/7\"\n",
        "    N8 =\"/content/gdrive/MyDrive/data/testing_data/8\"\n",
        "    N9 =\"/content/gdrive/MyDrive/data/testing_data/9\"\n",
        "    A=\"/content/gdrive/MyDrive/data/testing_data/A\"\n",
        "    B=\"/content/gdrive/MyDrive/data/testing_data/B\"\n",
        "    C=\"/content/gdrive/MyDrive/data/testing_data/C\"\n",
        "    D=\"/content/gdrive/MyDrive/data/testing_data/D\"\n",
        "    E=\"/content/gdrive/MyDrive/data/testing_data/E\"\n",
        "    F=\"/content/gdrive/MyDrive/data/testing_data/F\"\n",
        "    G=\"/content/gdrive/MyDrive/data/testing_data/G\"\n",
        "    H=\"/content/gdrive/MyDrive/data/testing_data/H\"\n",
        "    I=\"/content/gdrive/MyDrive/data/testing_data/I\"\n",
        "    J=\"/content/gdrive/MyDrive/data/testing_data/J\"\n",
        "    K=\"/content/gdrive/MyDrive/data/testing_data/K\"\n",
        "    L=\"/content/gdrive/MyDrive/data/testing_data/L\"\n",
        "    M=\"/content/gdrive/MyDrive/data/testing_data/M\"\n",
        "    N=\"/content/gdrive/MyDrive/data/testing_data/N\"\n",
        "    O=\"/content/gdrive/MyDrive/data/testing_data/O\"\n",
        "    P=\"/content/gdrive/MyDrive/data/testing_data/P\"\n",
        "    Q=\"/content/gdrive/MyDrive/data/testing_data/Q\"\n",
        "    R=\"/content/gdrive/MyDrive/data/testing_data/R\"\n",
        "    S=\"/content/gdrive/MyDrive/data/testing_data/S\"\n",
        "    T=\"/content/gdrive/MyDrive/data/testing_data/T\"\n",
        "    U=\"/content/gdrive/MyDrive/data/testing_data/U\"\n",
        "    V=\"/content/gdrive/MyDrive/data/testing_data/V\"\n",
        "    W=\"/content/gdrive/MyDrive/data/testing_data/W\"\n",
        "    X=\"/content/gdrive/MyDrive/data/testing_data/X\"\n",
        "    Y=\"/content/gdrive/MyDrive/data/testing_data/Y\"\n",
        "    Z=\"/content/gdrive/MyDrive/data/testing_data/Z\"\n",
        "\n",
        "    #LABELS = {N0:0,'N1':1,'N2':2,'N3':3,'N4':4,'N5':5,'N6':6,'N7':7,'N8':8,'N9':9,'A':10,'B':11,'C':12,'D':13,'E':14,'F':15,'G':16,'H':17,'I':18,'J':19,'K':20,'L':21,'M':22,'N':23,'O':24,'P':25,'Q':26,'R':27,'S':28,'T':29,'U':30,'V':31,'W':32,'X':33,'Y':34,'Z':35}\n",
        "    LABELS = {N0:0,N1:1,N2:2,N3:3,N4:4,N5:5,N6:6,N7:7,N8:8,N9:9,A:10,B:11,C:12,D:13,E:14,F:15,G:16,H:17,I:18,J:19,K:20,L:21,M:22,N:23,O:24,P:25,Q:26,R:27,S:28,T:29,U:30,V:31,W:32,X:33,Y:34,Z:35}\n",
        "    #COUNTS = {N0:0,'N1':0,'N2':0,'N3':0,'N4':0,'N5':0,'N6':0,'N7':0,'N8':0,'N9':0,'A':0,'B':0,'C':0,'D':0,'E':0,'F':0,'G':0,'H':0,'I':0,'J':0,'K':0,'L':0,'M':0,'N':0,'O':0,'P':0,'Q':0,'R':0,'S':0,'T':0,'U':0,'V':0,'W':0,'X':0,'Y':0,'Z':0}\n",
        "    COUNTS = {N0:0,N1:0,N2:0,N3:0,N4:0,N5:0,N6:0,N7:0,N8:0,N9:0,A:0,B:0,C:0,D:0,E:0,F:0,G:0,H:0,I:0,J:0,K:0,L:0,M:0,N:0,O:0,P:0,Q:0,R:0,S:0,T:0,U:0,V:0,W:0,X:0,Y:0,Z:0}\n",
        "\n",
        "    testing_data = []\n",
        "\n",
        "\n",
        "    def make_testing_data(self):\n",
        "        for label in self.LABELS:\n",
        "            for f in tqdm(os.listdir(label)):         #for f in tqdm(os.listdir(self.testing_data_path)):\n",
        "                    try:\n",
        "                        path = os.path.join(label, f)\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
        "                        self.testing_data.append([np.array(img), np.eye(36)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot\n",
        "                        #print(np.eye(36)[self.LABELS[label]])\n",
        "                        for count in self.COUNTS:\n",
        "                          if label==count:\n",
        "                            self.COUNTS[count]+=1\n",
        "                    except Exception as e:\n",
        "                          pass\n",
        "\n",
        "\n",
        "        np.random.shuffle(self.testing_data)\n",
        "        np.save(\"testing_data.npy\", self.testing_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc.\n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")\n",
        "\n",
        "\n",
        "if REBUILD_DATA_test:\n",
        "    alphavsnum_test = Alpha_num_test()\n",
        "    alphavsnum_test.make_testing_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-ZbuE4um5Xk",
        "outputId": "d36fbb08-053c-4e9d-c2b6-e40f9cbc8466"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on the GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28/28 [00:14<00:00,  1.96it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.05it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.00it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.06it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.04it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.03it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.08it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.00it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.03it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.03it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.07it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.14it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.05it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.06it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.09it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.06it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.04it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.08it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.04it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.08it/s]\n",
            "100%|██████████| 28/28 [00:14<00:00,  1.98it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.06it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.09it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.08it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.03it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.05it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.01it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.04it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.08it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.07it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.04it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.07it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.14it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.02it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.10it/s]\n",
            "100%|██████████| 28/28 [00:13<00:00,  2.08it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data = np.load(\"testing_data.npy\", allow_pickle=True)\n"
      ],
      "metadata": {
        "id": "vw23wbFsnMcl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.Tensor([i[0] for i in testing_data]).view(-1, 50, 50)\n",
        "X = X/255.0\n",
        "y = torch.Tensor([i[1] for i in testing_data])\n",
        "\n",
        "test_X = X\n",
        "test_y = y"
      ],
      "metadata": {
        "id": "VVvlw0MMnh9T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(test_X))):\n",
        "            real_class = torch.argmax(test_y[i]).to(device)\n",
        "            net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0]\n",
        "\n",
        "            predicted_class = torch.argmax(net_out)\n",
        "            if predicted_class == real_class:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "    print(\"Accuracy:\", round(correct/total*100,2))\n"
      ],
      "metadata": {
        "id": "CIkzek5ini1e"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGNkl47IntnO",
        "outputId": "13616d0e-f6e4-41db-a67e-233c3dd73773"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1008/1008 [00:00<00:00, 1201.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 98.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xf9TOaP0pKzQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
