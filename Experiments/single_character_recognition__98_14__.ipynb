{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install opencv-python\n",
        "# !pip install tensorflow\n"
      ],
      "metadata": {
        "id": "LeAZpSkxrmaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGAHbwYCZdrU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSB8w-XjAt6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#training and testing data paths"
      ],
      "metadata": {
        "id": "z8__yA0LPl09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path= '/content/drive/My Drive/data2/training_data/'\n",
        "test_data_path= '/content/drive/My Drive/testing_data/'\n",
        "\n",
        "class_names = sorted(os.listdir(train_data_path))\n",
        "n_classes=len(class_names)\n",
        "\n"
      ],
      "metadata": {
        "id": "0Dd3DCX2htm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(class_names)\n",
        "print(n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsN5E-mcDgnD",
        "outputId": "3652ebd3-457c-4d8d-95ab-e879b35e6eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
            "36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making training dataframe"
      ],
      "metadata": {
        "id": "p_hCa2-KPuDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_image_paths = []\n",
        "train_labels = []\n",
        "\n",
        "for folder_name in os.listdir(train_data_path):\n",
        "    folder_path = os.path.join(train_data_path, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        images = os.listdir(folder_path)\n",
        "        for image_name in images:\n",
        "            image_path = os.path.join(folder_path, image_name)\n",
        "            train_image_paths.append(image_path)\n",
        "            train_labels.append(class_names.index(folder_name))\n",
        "\n",
        "\n",
        "train_data = {'image_path': train_image_paths, 'label': train_labels}\n",
        "train_df = pd.DataFrame(train_data)"
      ],
      "metadata": {
        "id": "Q9zmJekR6GoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y8-XIQG5Dt46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making test dataframe"
      ],
      "metadata": {
        "id": "13MVfPJBPzNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_paths = []\n",
        "test_y = []\n",
        "\n",
        "for folder_name in os.listdir(test_data_path):\n",
        "    folder_path = os.path.join(test_data_path, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        images = os.listdir(folder_path)\n",
        "        for image_name in images:\n",
        "            image_path = os.path.join(folder_path, image_name)\n",
        "            test_paths.append(image_path)\n",
        "            test_y.append(class_names.index(folder_name))\n",
        "\n",
        "test_data = {'image_path': test_paths, 'label': test_y}\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "hELplpJWw_1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making validation data by splitting test data"
      ],
      "metadata": {
        "id": "RwDQ1zEhP2T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_images = test_df['image_path']\n",
        "test_l = test_df['label']\n",
        "\n",
        "test_image_paths, valid_image_paths, test_labels, valid_labels = train_test_split(\n",
        "    test_images, test_l, test_size=0.2, random_state=42)\n",
        "\n",
        "test_data = {'image_path': test_image_paths, 'label': test_labels}\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n",
        "valid_data = {'image_path': valid_image_paths, 'label': valid_labels}\n",
        "valid_df = pd.DataFrame(valid_data)"
      ],
      "metadata": {
        "id": "8aMMXHhDzPTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_paths=test_image_paths.tolist()\n",
        "test_labels=test_labels.tolist()\n",
        "\n",
        "valid_image_paths=valid_image_paths.tolist()\n",
        "valid_labels=valid_labels.tolist()"
      ],
      "metadata": {
        "id": "qiH7u4C6sHjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwHp7OR6At2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function to customize dataset"
      ],
      "metadata": {
        "id": "dvu2nuOkPSoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.labels[index]\n",
        "        return image, label\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "batch_size = 16\n",
        "learning_rate = 0.001\n",
        "num_epochs = 15\n",
        "\n",
        "#transform function\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((120, 120)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n"
      ],
      "metadata": {
        "id": "hmxR0b3Ke0iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#making dataloaders"
      ],
      "metadata": {
        "id": "YzrnanMfPM0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = CustomDataset(train_image_paths, train_labels, transform=transform)\n",
        "test_dataset=CustomDataset(test_image_paths, test_labels, transform=transform)\n",
        "valid_dataset=CustomDataset(valid_image_paths, valid_labels, transform=transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "gWqDVUmfiQB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing data"
      ],
      "metadata": {
        "id": "MYEbCQE5O9U8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader))\n",
        "print(len(test_loader))\n",
        "print(len(valid_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHiGYVMCfhdj",
        "outputId": "d7cda1aa-3263-4f33-bb8d-e795b154d08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "646\n",
            "51\n",
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "  # print(batch)\n",
        "  x,y=batch\n",
        "  print(x.shape)\n",
        "  print(y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o308hbrBfPjA",
        "outputId": "8337f821-5af5-47c7-c360-32b3e24887b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 120, 120])\n",
            "tensor([34, 30,  0,  9,  7,  9, 26, 15, 20, 20,  3, 15,  7, 15,  3, 12,  6, 15,\n",
            "         1, 25, 33, 10, 18,  0, 19,  9, 32, 23,  4, 29, 14,  3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in valid_loader:\n",
        "  # print(batch)\n",
        "  x,y=batch\n",
        "  print(x.shape)\n",
        "  print(y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xePC9ldLdOuv",
        "outputId": "f23a681d-279a-459f-bc80-673edc8740f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 3, 120, 120])\n",
            "tensor([ 1,  7, 24, 18, 19, 19, 25, 23, 19, 13, 35, 29, 17,  0, 33, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in test_loader:\n",
        "  # print(batch)\n",
        "  x,y=batch\n",
        "  print(x.shape)\n",
        "  print(y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k75PYh3XdkN6",
        "outputId": "9e434ce8-2f17-4c2a-a682-8d4549764fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 3, 120, 120])\n",
            "tensor([ 4, 34,  3, 19, 15,  0, 21, 14,  8, 17, 18, 23, 27, 12, 16, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building an ANN model from pytorch"
      ],
      "metadata": {
        "id": "liWCS2lYO2IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(3 * 120 * 120, 128)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(64, 36)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "bkvNixqhgUYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "mBHXY_u0e-qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training our ANN model and Validating also with every epoch"
      ],
      "metadata": {
        "id": "NTDfrE0NOuma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # if (i + 1) % 2 == 0:\n",
        "        #     print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_step}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate validation accuracy\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "    average_val_loss = val_loss / len(valid_loader)\n",
        "\n",
        "    # Print training and validation statistics\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {average_loss:.4f}, \"\n",
        "          f\"Training Accuracy: {train_accuracy:.2f}%, Validation Loss: {average_val_loss:.4f}, \"\n",
        "          f\"Validation Accuracy: {val_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "HdPEhGfzioBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685bca77-021a-4f00-dcfe-9ce0ff0ace96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Training Loss: 2.5896, Training Accuracy: 55.03%, Validation Loss: 1.2871, Validation Accuracy: 86.63%\n",
            "Epoch [2/15], Training Loss: 0.9914, Training Accuracy: 87.12%, Validation Loss: 0.4788, Validation Accuracy: 94.06%\n",
            "Epoch [3/15], Training Loss: 0.5721, Training Accuracy: 90.23%, Validation Loss: 0.3018, Validation Accuracy: 94.06%\n",
            "Epoch [4/15], Training Loss: 0.4409, Training Accuracy: 91.35%, Validation Loss: 0.2336, Validation Accuracy: 94.55%\n",
            "Epoch [5/15], Training Loss: 0.3756, Training Accuracy: 92.23%, Validation Loss: 0.1774, Validation Accuracy: 97.52%\n",
            "Epoch [6/15], Training Loss: 0.3348, Training Accuracy: 92.71%, Validation Loss: 0.1541, Validation Accuracy: 97.52%\n",
            "Epoch [7/15], Training Loss: 0.3066, Training Accuracy: 93.14%, Validation Loss: 0.1335, Validation Accuracy: 97.52%\n",
            "Epoch [8/15], Training Loss: 0.2859, Training Accuracy: 93.44%, Validation Loss: 0.1179, Validation Accuracy: 98.02%\n",
            "Epoch [9/15], Training Loss: 0.2696, Training Accuracy: 93.74%, Validation Loss: 0.1098, Validation Accuracy: 98.02%\n",
            "Epoch [10/15], Training Loss: 0.2565, Training Accuracy: 93.83%, Validation Loss: 0.0943, Validation Accuracy: 98.02%\n",
            "Epoch [11/15], Training Loss: 0.2452, Training Accuracy: 94.15%, Validation Loss: 0.0988, Validation Accuracy: 98.02%\n",
            "Epoch [12/15], Training Loss: 0.2358, Training Accuracy: 94.25%, Validation Loss: 0.0868, Validation Accuracy: 98.02%\n",
            "Epoch [13/15], Training Loss: 0.2278, Training Accuracy: 94.30%, Validation Loss: 0.0816, Validation Accuracy: 98.02%\n",
            "Epoch [14/15], Training Loss: 0.2208, Training Accuracy: 94.49%, Validation Loss: 0.0909, Validation Accuracy: 98.02%\n",
            "Epoch [15/15], Training Loss: 0.2142, Training Accuracy: 94.60%, Validation Loss: 0.0803, Validation Accuracy: 98.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the ANN model"
      ],
      "metadata": {
        "id": "5cZLaK3COaDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = 100 * test_correct / test_total\n",
        "average_test_loss = test_loss / len(test_loader)\n",
        "\n",
        "# Print test statistics\n",
        "print(f\"Test Loss: {average_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "HBL8Q14pin8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6918ec71-b582-4602-e1b1-8d5ab336587f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0828, Test Accuracy: 98.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving the model"
      ],
      "metadata": {
        "id": "-XFbVFtyOd4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = 'ANN_model_for_characters'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "save_path = os.path.join(save_dir, 'model')\n",
        "torch.save(model, save_path)"
      ],
      "metadata": {
        "id": "yAoRs1o83oN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function to predict image\n",
        "(takes the path of picture and model)"
      ],
      "metadata": {
        "id": "9LeugsWLOgNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_image_label(image_path, model):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((120, 120)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        return class_names[predicted.item()]\n"
      ],
      "metadata": {
        "id": "S_vyr94Sin6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_image_label('/content/drive/My Drive/data2/testing_data/0/37908.png',model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3Vfvzmh21kD",
        "outputId": "f018c9ed-2277-4b8d-e5c2-a6d09050dc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B7tMwzpO3nyY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}