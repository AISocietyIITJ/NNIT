{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLw1WKmpjHEW",
        "outputId": "f154dd15-0f3c-486b-f1c9-e99e957da797"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXIdTefKieQ8",
        "outputId": "48007fa5-9869-4d22-a2b3-6c3fd212eb34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.10/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htQqW-uGizVU",
        "outputId": "3e316d77-386b-4b64-9a07-e67cb5949835"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "#{\"username\":\"pari16\",\"key\":\"dfd22a0d64f82186cd7db7c1a9af2044\"}\n",
        "od.download(\"https://www.kaggle.com/datasets/preatcher/standard-ocr-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JzGp3CawguS",
        "outputId": "847f69f5-251b-4562-9cba-f70422be2005"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./standard-ocr-dataset\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "6ch_rWg0rFKr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_path=\"/content/standard-ocr-dataset/data/training_data\"\n",
        "training_data=[]\n",
        "import os\n",
        "for label in os.listdir(training_data_path):#os.listdir(training_data_path) gives list of list of 0 images,1 images etc =[0,1,2,3,4,5,6,7,8,9,'A','B',....,'Z']\n",
        "  for j in os.listdir(os.path.join(training_data_path,label)):\n",
        "    training_data.append([os.path.join(training_data_path,label,j),label])\n"
      ],
      "metadata": {
        "id": "EDzBAZuHiYqC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS = {'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,'A':10,'B':11,'C':12,'D':13,'E':14,'F':15,'G':16,'H':17,'I':18,'J':19,'K':20,'L':21,'M':22,'N':23,'O':24,'P':25,'Q':26,'R':27,'S':28,'T':29,'U':30,'V':31,'W':32,'X':33,'Y':34,'Z':35}"
      ],
      "metadata": {
        "id": "GC9JoZO7Wsfb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize to imagenet size\n",
        "transform = Compose([Resize((224, 224)), ToTensor()])\n"
      ],
      "metadata": {
        "id": "uP7bHI0GxIMP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "class Train_Dataset(Dataset):\n",
        "  def __init__(self,img_list):\n",
        "    self.img_list=img_list\n",
        "  def __getitem__(self,index):\n",
        "    path=self.img_list[index][0]\n",
        "    label=self.img_list[index][1]\n",
        "    one_hot= np.eye(36)[LABELS[label]]\n",
        "    img=Image.open(path)\n",
        "    #img=transform(img)\n",
        "    x=transform(img)\n",
        "    #x = x.unsqueeze(0)\n",
        "    return [x,one_hot]     #return[img,label]\n",
        "  def __len__(self):\n",
        "    return len(self.img_list)\n"
      ],
      "metadata": {
        "id": "UgCWI5eMJyMJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader=DataLoader(Train_Dataset(training_data))"
      ],
      "metadata": {
        "id": "w4RdE8-lRxt5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_dataloader:\n",
        "  print(i[1])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtD4_yKDeWqU",
        "outputId": "d507d793-01d1-4b2b-a9f9-46bd47bb6ef9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 16            # 16 pixels\n",
        "for i in train_dataloader:\n",
        "  pathes = rearrange(i[0], 'b c (h s1) (w s2) -> b (h w) (s1 s2 c)', s1=patch_size, s2=patch_size)"
      ],
      "metadata": {
        "id": "BbDrUWvtESUS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data_path=\"/content/standard-ocr-dataset/data/testing_data\"\n",
        "testing_data=[]\n",
        "import os\n",
        "for label in os.listdir(testing_data_path):#os.listdir(testing_data_path) gives list of list of 0 images,1 images etc =[0,1,2,3,4,5,6,7,8,9,'A','B',....,'Z']\n",
        "  for j in os.listdir(os.path.join(testing_data_path,label)):\n",
        "    testing_data.append([os.path.join(testing_data_path,label,j),label])"
      ],
      "metadata": {
        "id": "FKJHb184DiLQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Test_Dataset(Dataset):\n",
        "  def __init__(self,img_list):\n",
        "    self.img_list=img_list\n",
        "  def __getitem__(self,index):\n",
        "    path=self.img_list[index][0]\n",
        "    label=self.img_list[index][1]\n",
        "    one_hot= np.eye(36)[LABELS[label]]\n",
        "    img=Image.open(path)\n",
        "    #img=transform(img)\n",
        "    x=transform(img)\n",
        "    #x = x.unsqueeze(0)\n",
        "    return [x,one_hot]     #return[img,label]\n",
        "  def __len__(self):\n",
        "    return len(self.img_list)"
      ],
      "metadata": {
        "id": "qv6S7MUTDiV0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader=DataLoader(Test_Dataset(testing_data))"
      ],
      "metadata": {
        "id": "pYRkdq63Digr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in test_dataloader:\n",
        "  print(i[1])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvg2jOeqYJg3",
        "outputId": "6d45bcb3-a9f7-405e-bb5a-f15e10b4e895"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''for i in train_dataloader:\n",
        "  print(i[0].shape)            #torch.Size([1,1, 224, 224])\n",
        "  break'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GXkpKuDSqwkA",
        "outputId": "26e8445b-45b6-4af7-9e7a-9c947ed4b46f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for i in train_dataloader:\\n  print(i[0].shape)            #torch.Size([1,1, 224, 224])\\n  break'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 16            # 16 pixels\n",
        "for i in test_dataloader:\n",
        "  pathes = rearrange(i[0], 'b c (h s1) (w s2) -> b (h w) (s1 s2 c)', s1=patch_size, s2=patch_size)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wt2WYarIfDst"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, in_channels= 1, patch_size= 16, emb_size= 128, img_size= 224):\n",
        "        self.patch_size = patch_size\n",
        "        super().__init__()\n",
        "        '''self.projection = nn.Sequential(\n",
        "            # break-down the image in s1 x s2 patches and flat them\n",
        "            Rearrange('b c (h s1) (w s2) -> b (h w) (s1 s2 c)', s1=patch_size, s2=patch_size),         #size is 196X256\n",
        "            nn.Linear(patch_size * patch_size * in_channels, emb_size)                                 # size is 768X128\n",
        "        )'''\n",
        "        self.projection = nn.Sequential(\n",
        "            # using a conv layer instead of a linear one -> performance gains\n",
        "            nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
        "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
        "        )\n",
        "        self.cls_token = nn.Parameter(torch.randn(1,1, emb_size))\n",
        "        self.positions = nn.Parameter(torch.randn((img_size // patch_size) **2 + 1, emb_size))\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        b, _, _, _ = x.shape\n",
        "        #print(\"Input shape:\", x.shape)\n",
        "        x = self.projection(x)\n",
        "        #print(\"Intermediate shape:\", x.shape)\n",
        "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
        "        # prepend the cls token to the input\n",
        "        x = torch.cat([cls_tokens, x], dim=1)\n",
        "        # add position embedding\n",
        "        x += self.positions\n",
        "        return x\n",
        "\n",
        "\n",
        "for i in train_dataloader:\n",
        "  print(PatchEmbedding()(i[0]).shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LCEtr_ffEdc",
        "outputId": "d870e86a-5226-4c1a-8308-36f7bff46da9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 197, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size = 128, num_heads = 8, dropout = 0):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        # fuse the queries, keys and values in one matrix\n",
        "        self.qkv = nn.Linear(emb_size, emb_size * 3)\n",
        "        self.att_drop = nn.Dropout(dropout)\n",
        "        self.projection = nn.Linear(emb_size, emb_size)\n",
        "\n",
        "    def forward(self, x : Tensor, mask: Tensor = None) -> Tensor:\n",
        "        # split keys, queries and values in num_heads\n",
        "        qkv = rearrange(self.qkv(x), \"b n (h d qkv) -> (qkv) b h n d\", h=self.num_heads, qkv=3)\n",
        "        queries, keys, values = qkv[0], qkv[1], qkv[2]\n",
        "        # sum up over the last axis\n",
        "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) # batch, num_heads, query_len, key_len\n",
        "        if mask is not None:\n",
        "            fill_value = torch.finfo(torch.float32).min\n",
        "            energy.mask_fill(~mask, fill_value)\n",
        "\n",
        "        scaling = self.emb_size ** (1/2)\n",
        "        att = F.softmax(energy, dim=-1) / scaling\n",
        "        att = self.att_drop(att)\n",
        "        # sum up over the third axis\n",
        "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
        "        out = self.projection(out)\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "n7BN_ICtneau"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"the embedding size refers to the number of features or dimensions used to represent each item in a dataset\""
      ],
      "metadata": {
        "id": "krjQ796QA-Da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualAdd(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):     #**kwargs, which is a special syntax that allows passing additional keyword arguments if needed.\n",
        "        res = x\n",
        "        x = self.fn(x, **kwargs)\n",
        "        x += res\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "f1vgz5QynizM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardBlock(nn.Sequential):\n",
        "    def __init__(self, emb_size, expansion= 4, drop_p= 0.):\n",
        "        super().__init__(\n",
        "            nn.Linear(emb_size, expansion * emb_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop_p),\n",
        "            nn.Linear(expansion * emb_size, emb_size),\n",
        "        )\n"
      ],
      "metadata": {
        "id": "scyNrYBUnlRU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 emb_size: int = 128,\n",
        "                 drop_p: float = 0.,\n",
        "                 forward_expansion: int = 4,\n",
        "                 forward_drop_p: float = 0.,\n",
        "                 ** kwargs):\n",
        "        super().__init__(\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                MultiHeadAttention(emb_size, **kwargs),\n",
        "                nn.Dropout(drop_p)\n",
        "            )),\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                FeedForwardBlock(\n",
        "                    emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
        "                nn.Dropout(drop_p)\n",
        "            )\n",
        "            ))\n"
      ],
      "metadata": {
        "id": "W4d2gnMynn42"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Sequential):\n",
        "    def __init__(self, depth: int = 12, **kwargs):\n",
        "        super().__init__(*[TransformerEncoderBlock(**kwargs) for _ in range(depth)])\n"
      ],
      "metadata": {
        "id": "hOvlFKPlntef"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationHead(nn.Sequential):\n",
        "    def __init__(self, emb_size = 128, n_classes =36):\n",
        "        super().__init__(\n",
        "            Reduce('b n e -> b e', reduction='mean'),\n",
        "            nn.LayerNorm(emb_size),\n",
        "            nn.Linear(emb_size, n_classes))\n"
      ],
      "metadata": {
        "id": "xSnsa132nxrK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "4gXQEwiAJDCj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                in_channels= 1,\n",
        "                patch_size= 16,\n",
        "                emb_size= 128,\n",
        "                img_size= 224,\n",
        "                depth= 12,\n",
        "                n_classes= 36,\n",
        "                **kwargs):\n",
        "        super().__init__(\n",
        "            PatchEmbedding(in_channels, patch_size, emb_size, img_size),\n",
        "            TransformerEncoder(depth, emb_size=emb_size, **kwargs),\n",
        "            ClassificationHead(emb_size, n_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    #train_dataloader=train_dataloader.type(torch.LongTensor)\n",
        "\n",
        "    def train(self,EPOCHS=10):\n",
        "\n",
        "      optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
        "      #loss_function=nn.MSELoss()\n",
        "      loss_function = nn.CrossEntropyLoss()\n",
        "      self.EPOCHS=EPOCHS\n",
        "\n",
        "      '''for epoch in range(self.EPOCHS):\n",
        "        for batch_X, batch_y in train_dataloader:  # Unpack the batch data and labels properly\n",
        "            optimizer.zero_grad()\n",
        "            outputs = self.forward(batch_X)\n",
        "            loss = loss_function(outputs, batch_y)  # Use batch_y directly as the target\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(loss)'''\n",
        "      for epoch in range(self.EPOCHS):\n",
        "        for i in train_dataloader:\n",
        "            batch_X,batch_y=i\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = self.forward(batch_X)\n",
        "           # batch_y = batch_y.view(-1)\n",
        "            #outputs=outputs.t()\n",
        "           #print(outputs.shape)\n",
        "           # print(batch_y.shape)\n",
        "            loss = loss_function(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(loss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def test(self):\n",
        "      correct = 0\n",
        "      total = len(test_dataloader)\n",
        "     # with torch.no_grad():\n",
        "      for i in test_dataloader:\n",
        "        test_X,test_y=i\n",
        "        output=self.forward(test_X)\n",
        "\n",
        "        for j in range(len(test_y)):\n",
        "          real_class = torch.argmax(test_y,1)[j]\n",
        "          predicted_class = torch.argmax(output,1)[j]\n",
        "        if predicted_class == real_class:\n",
        "            correct += 1\n",
        "\n",
        "      print(\"Accuracy:\", round(correct/total*100,2))\n"
      ],
      "metadata": {
        "id": "MHflRADsnyN0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit=ViT().cuda()"
      ],
      "metadata": {
        "id": "DANtfQJKOG4n"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit.train()"
      ],
      "metadata": {
        "id": "CEFNygURwhF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit.test()"
      ],
      "metadata": {
        "id": "OgzXjUKlxiVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(vit,(1,224,224))"
      ],
      "metadata": {
        "id": "uXy9JaL9nyRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ef4f24-8497-4840-a864-8d69eb56bc25"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 128, 14, 14]          32,896\n",
            "         Rearrange-2             [-1, 196, 128]               0\n",
            "    PatchEmbedding-3             [-1, 197, 128]               0\n",
            "         LayerNorm-4             [-1, 197, 128]             256\n",
            "            Linear-5             [-1, 197, 384]          49,536\n",
            "           Dropout-6          [-1, 8, 197, 197]               0\n",
            "            Linear-7             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-8             [-1, 197, 128]               0\n",
            "           Dropout-9             [-1, 197, 128]               0\n",
            "      ResidualAdd-10             [-1, 197, 128]               0\n",
            "        LayerNorm-11             [-1, 197, 128]             256\n",
            "           Linear-12             [-1, 197, 512]          66,048\n",
            "             GELU-13             [-1, 197, 512]               0\n",
            "          Dropout-14             [-1, 197, 512]               0\n",
            "           Linear-15             [-1, 197, 128]          65,664\n",
            "          Dropout-16             [-1, 197, 128]               0\n",
            "      ResidualAdd-17             [-1, 197, 128]               0\n",
            "        LayerNorm-18             [-1, 197, 128]             256\n",
            "           Linear-19             [-1, 197, 384]          49,536\n",
            "          Dropout-20          [-1, 8, 197, 197]               0\n",
            "           Linear-21             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-22             [-1, 197, 128]               0\n",
            "          Dropout-23             [-1, 197, 128]               0\n",
            "      ResidualAdd-24             [-1, 197, 128]               0\n",
            "        LayerNorm-25             [-1, 197, 128]             256\n",
            "           Linear-26             [-1, 197, 512]          66,048\n",
            "             GELU-27             [-1, 197, 512]               0\n",
            "          Dropout-28             [-1, 197, 512]               0\n",
            "           Linear-29             [-1, 197, 128]          65,664\n",
            "          Dropout-30             [-1, 197, 128]               0\n",
            "      ResidualAdd-31             [-1, 197, 128]               0\n",
            "        LayerNorm-32             [-1, 197, 128]             256\n",
            "           Linear-33             [-1, 197, 384]          49,536\n",
            "          Dropout-34          [-1, 8, 197, 197]               0\n",
            "           Linear-35             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-36             [-1, 197, 128]               0\n",
            "          Dropout-37             [-1, 197, 128]               0\n",
            "      ResidualAdd-38             [-1, 197, 128]               0\n",
            "        LayerNorm-39             [-1, 197, 128]             256\n",
            "           Linear-40             [-1, 197, 512]          66,048\n",
            "             GELU-41             [-1, 197, 512]               0\n",
            "          Dropout-42             [-1, 197, 512]               0\n",
            "           Linear-43             [-1, 197, 128]          65,664\n",
            "          Dropout-44             [-1, 197, 128]               0\n",
            "      ResidualAdd-45             [-1, 197, 128]               0\n",
            "        LayerNorm-46             [-1, 197, 128]             256\n",
            "           Linear-47             [-1, 197, 384]          49,536\n",
            "          Dropout-48          [-1, 8, 197, 197]               0\n",
            "           Linear-49             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-50             [-1, 197, 128]               0\n",
            "          Dropout-51             [-1, 197, 128]               0\n",
            "      ResidualAdd-52             [-1, 197, 128]               0\n",
            "        LayerNorm-53             [-1, 197, 128]             256\n",
            "           Linear-54             [-1, 197, 512]          66,048\n",
            "             GELU-55             [-1, 197, 512]               0\n",
            "          Dropout-56             [-1, 197, 512]               0\n",
            "           Linear-57             [-1, 197, 128]          65,664\n",
            "          Dropout-58             [-1, 197, 128]               0\n",
            "      ResidualAdd-59             [-1, 197, 128]               0\n",
            "        LayerNorm-60             [-1, 197, 128]             256\n",
            "           Linear-61             [-1, 197, 384]          49,536\n",
            "          Dropout-62          [-1, 8, 197, 197]               0\n",
            "           Linear-63             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-64             [-1, 197, 128]               0\n",
            "          Dropout-65             [-1, 197, 128]               0\n",
            "      ResidualAdd-66             [-1, 197, 128]               0\n",
            "        LayerNorm-67             [-1, 197, 128]             256\n",
            "           Linear-68             [-1, 197, 512]          66,048\n",
            "             GELU-69             [-1, 197, 512]               0\n",
            "          Dropout-70             [-1, 197, 512]               0\n",
            "           Linear-71             [-1, 197, 128]          65,664\n",
            "          Dropout-72             [-1, 197, 128]               0\n",
            "      ResidualAdd-73             [-1, 197, 128]               0\n",
            "        LayerNorm-74             [-1, 197, 128]             256\n",
            "           Linear-75             [-1, 197, 384]          49,536\n",
            "          Dropout-76          [-1, 8, 197, 197]               0\n",
            "           Linear-77             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-78             [-1, 197, 128]               0\n",
            "          Dropout-79             [-1, 197, 128]               0\n",
            "      ResidualAdd-80             [-1, 197, 128]               0\n",
            "        LayerNorm-81             [-1, 197, 128]             256\n",
            "           Linear-82             [-1, 197, 512]          66,048\n",
            "             GELU-83             [-1, 197, 512]               0\n",
            "          Dropout-84             [-1, 197, 512]               0\n",
            "           Linear-85             [-1, 197, 128]          65,664\n",
            "          Dropout-86             [-1, 197, 128]               0\n",
            "      ResidualAdd-87             [-1, 197, 128]               0\n",
            "        LayerNorm-88             [-1, 197, 128]             256\n",
            "           Linear-89             [-1, 197, 384]          49,536\n",
            "          Dropout-90          [-1, 8, 197, 197]               0\n",
            "           Linear-91             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-92             [-1, 197, 128]               0\n",
            "          Dropout-93             [-1, 197, 128]               0\n",
            "      ResidualAdd-94             [-1, 197, 128]               0\n",
            "        LayerNorm-95             [-1, 197, 128]             256\n",
            "           Linear-96             [-1, 197, 512]          66,048\n",
            "             GELU-97             [-1, 197, 512]               0\n",
            "          Dropout-98             [-1, 197, 512]               0\n",
            "           Linear-99             [-1, 197, 128]          65,664\n",
            "         Dropout-100             [-1, 197, 128]               0\n",
            "     ResidualAdd-101             [-1, 197, 128]               0\n",
            "       LayerNorm-102             [-1, 197, 128]             256\n",
            "          Linear-103             [-1, 197, 384]          49,536\n",
            "         Dropout-104          [-1, 8, 197, 197]               0\n",
            "          Linear-105             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-106             [-1, 197, 128]               0\n",
            "         Dropout-107             [-1, 197, 128]               0\n",
            "     ResidualAdd-108             [-1, 197, 128]               0\n",
            "       LayerNorm-109             [-1, 197, 128]             256\n",
            "          Linear-110             [-1, 197, 512]          66,048\n",
            "            GELU-111             [-1, 197, 512]               0\n",
            "         Dropout-112             [-1, 197, 512]               0\n",
            "          Linear-113             [-1, 197, 128]          65,664\n",
            "         Dropout-114             [-1, 197, 128]               0\n",
            "     ResidualAdd-115             [-1, 197, 128]               0\n",
            "       LayerNorm-116             [-1, 197, 128]             256\n",
            "          Linear-117             [-1, 197, 384]          49,536\n",
            "         Dropout-118          [-1, 8, 197, 197]               0\n",
            "          Linear-119             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-120             [-1, 197, 128]               0\n",
            "         Dropout-121             [-1, 197, 128]               0\n",
            "     ResidualAdd-122             [-1, 197, 128]               0\n",
            "       LayerNorm-123             [-1, 197, 128]             256\n",
            "          Linear-124             [-1, 197, 512]          66,048\n",
            "            GELU-125             [-1, 197, 512]               0\n",
            "         Dropout-126             [-1, 197, 512]               0\n",
            "          Linear-127             [-1, 197, 128]          65,664\n",
            "         Dropout-128             [-1, 197, 128]               0\n",
            "     ResidualAdd-129             [-1, 197, 128]               0\n",
            "       LayerNorm-130             [-1, 197, 128]             256\n",
            "          Linear-131             [-1, 197, 384]          49,536\n",
            "         Dropout-132          [-1, 8, 197, 197]               0\n",
            "          Linear-133             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-134             [-1, 197, 128]               0\n",
            "         Dropout-135             [-1, 197, 128]               0\n",
            "     ResidualAdd-136             [-1, 197, 128]               0\n",
            "       LayerNorm-137             [-1, 197, 128]             256\n",
            "          Linear-138             [-1, 197, 512]          66,048\n",
            "            GELU-139             [-1, 197, 512]               0\n",
            "         Dropout-140             [-1, 197, 512]               0\n",
            "          Linear-141             [-1, 197, 128]          65,664\n",
            "         Dropout-142             [-1, 197, 128]               0\n",
            "     ResidualAdd-143             [-1, 197, 128]               0\n",
            "       LayerNorm-144             [-1, 197, 128]             256\n",
            "          Linear-145             [-1, 197, 384]          49,536\n",
            "         Dropout-146          [-1, 8, 197, 197]               0\n",
            "          Linear-147             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-148             [-1, 197, 128]               0\n",
            "         Dropout-149             [-1, 197, 128]               0\n",
            "     ResidualAdd-150             [-1, 197, 128]               0\n",
            "       LayerNorm-151             [-1, 197, 128]             256\n",
            "          Linear-152             [-1, 197, 512]          66,048\n",
            "            GELU-153             [-1, 197, 512]               0\n",
            "         Dropout-154             [-1, 197, 512]               0\n",
            "          Linear-155             [-1, 197, 128]          65,664\n",
            "         Dropout-156             [-1, 197, 128]               0\n",
            "     ResidualAdd-157             [-1, 197, 128]               0\n",
            "       LayerNorm-158             [-1, 197, 128]             256\n",
            "          Linear-159             [-1, 197, 384]          49,536\n",
            "         Dropout-160          [-1, 8, 197, 197]               0\n",
            "          Linear-161             [-1, 197, 128]          16,512\n",
            "MultiHeadAttention-162             [-1, 197, 128]               0\n",
            "         Dropout-163             [-1, 197, 128]               0\n",
            "     ResidualAdd-164             [-1, 197, 128]               0\n",
            "       LayerNorm-165             [-1, 197, 128]             256\n",
            "          Linear-166             [-1, 197, 512]          66,048\n",
            "            GELU-167             [-1, 197, 512]               0\n",
            "         Dropout-168             [-1, 197, 512]               0\n",
            "          Linear-169             [-1, 197, 128]          65,664\n",
            "         Dropout-170             [-1, 197, 128]               0\n",
            "     ResidualAdd-171             [-1, 197, 128]               0\n",
            "          Reduce-172                  [-1, 128]               0\n",
            "       LayerNorm-173                  [-1, 128]             256\n",
            "          Linear-174                   [-1, 36]           4,644\n",
            "================================================================\n",
            "Total params: 2,417,060\n",
            "Trainable params: 2,417,060\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 84.41\n",
            "Params size (MB): 9.22\n",
            "Estimated Total Size (MB): 93.82\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "82KErdOqN3OZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}